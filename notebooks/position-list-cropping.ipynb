{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping an existing position list for manual re-imaging\n",
    "\n",
    "This notebook 'crops' a position list generated by the HCS Site Generator plugin by selecting a subset of the positions in the position list according to a user-specified list of wells. It then orders these positions according to the order of the wells in the user-specified list and saves the positions in a new position list.\n",
    "\n",
    "This is intended for manual redos in which the user selects a small number of wells to be re-imaged. Note that the order of these wells matters and is determined by the user in order to minimize stage movements, so it is important that the well order be preserved in the new position list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from dragonfly_automation import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test filepath\n",
    "position_list_filepath = (\n",
    "    '/Users/keith.cheveralls/image-data/dragonfly-automation-tests/'\n",
    "    'HCS_sites_20191009_INTERPOLATED.pos'\n",
    ")\n",
    "with open(position_list_filepath, 'r') as file:\n",
    "    position_list = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to the exported position list\n",
    "\n",
    "Generally, this position list should be the interpolated position list generated by the stage-position-interpolation notebook. Its filename should be of the form `'{date}_raw_positions_interpolated.pos'` and it should have been saved in the folder `D:\\MLPipeline\\position-lists\\`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "position_list_filename = '_raw_positions_interpolated.pos'\n",
    "\n",
    "position_list_filepath = os.path.join('D:', 'PipelineML', 'position-lists', position_list_filename)\n",
    "with open(position_list_filepath, 'r') as file:\n",
    "    position_list = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION 1: Manually define a list of wells to be re-imaged\n",
    "\n",
    "Here, we define the subset of wells to be re-imaged and the number of positions to visit in each well. This number must be less than or equal to the number of sites per well in the original position list. For example, if a 6x6 grid was used in the HCS Site Generator, then the number of sites per well would have to be 36 or less.\n",
    "\n",
    "__Please note: the order of the `well_ids` list is critical, because it is used to determine the order of the positions in the new position list, which in turn determines the order in which the microscope will visit the wells.__ Please make sure that the order you choose will not require any long* stage movements (if necessary, you can 'pad' the list with intermediate wells to break up any such long movements).\n",
    "\n",
    "*generally, 'long' means a distance of more than five wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_well_ids = ['B2']\n",
    "num_sites_per_well = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell without modification\n",
    "selected_positions = []\n",
    "all_positions = position_list['POSITIONS']\n",
    "for selected_well_id in selected_well_ids:\n",
    "    for position in all_positions:\n",
    "        well_id, site_num = utils.parse_hcs_site_label(position['LABEL'])\n",
    "        if well_id == selected_well_id and site_num < num_sites_per_well:\n",
    "            selected_positions.append(position)\n",
    "            \n",
    "print('%s positions selected' % len(selected_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for well_ids that were not found in the position list\n",
    "missing_well_ids = (\n",
    "    set(selected_well_ids)\n",
    "    .difference([utils.parse_hcs_site_label(p['LABEL'])[0] for p in selected_positions])\n",
    ")\n",
    "if missing_well_ids:\n",
    "    print('Warning: no positions were found for these well_ids: %s' % list(missing_well_ids))\n",
    "else:\n",
    "    print('Positions were found for all selected wells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cropped position list\n",
    "cropped_position_list = position_list.copy()\n",
    "cropped_position_list['POSITIONS'] = selected_positions\n",
    "\n",
    "dst_filepath = position_list_filepath.replace('.pos', '_cropped.pos')\n",
    "with open(dst_filepath, 'w') as file:\n",
    "    json.dump(cropped_position_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final sanity check: view the position labels explicitly\n",
    "[p['LABEL'] for p in selected_positions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION 2: Use the FOV scores from an existing acquisition\n",
    "\n",
    "Here, we crop the position list by only retaining the top-scoring positions in each well. The FOV scores are obtained from an existing acquisition, which must exist, and is assumed to be of the same plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the PML directory for the existing acquisition\n",
    "acquisition_dir = '/Users/keith.cheveralls/projects/dragonfly-automation/tests/output/PML0000-7'\n",
    "\n",
    "# define the number of highest-scoring positions in each well\n",
    "num_positions_per_well = 4\n",
    "\n",
    "score_log = pd.read_csv(os.path.join(exp_dir, 'logs', 'fov-scoring', 'fov-score-log.csv'))\n",
    "top_scores = (\n",
    "    score_log.sort_values(by=['position_well_id', 'score'], ascending=False)\n",
    "    .groupby('position_well_id')\n",
    "    .head(num_positions_per_well)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell without modification\n",
    "selected_positions = [\n",
    "    position for position in position_list['POSITIONS']\n",
    "    if position['LABEL'] in top_scores.position_label.values\n",
    "]\n",
    "\n",
    "print('%s positions selected' % len(selected_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for positions that were not found in the position list\n",
    "missing_position_labels = set(top_scores.position_label.values).difference([p['LABEL'] for p in selected_positions])\n",
    "if missing_position_labels:\n",
    "    print('Warning: these positions were not found in the position list: %s' % list(missing_position_labels))\n",
    "else:\n",
    "    print('All positions were found in the position list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final sanity check: view the position labels explicitly\n",
    "[p['LABEL'] for p in selected_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cropped position list\n",
    "cropped_position_list = position_list.copy()\n",
    "cropped_position_list['POSITIONS'] = selected_positions\n",
    "\n",
    "dst_filepath = position_list_filepath.replace('.pos', '_cropped.pos')\n",
    "with open(dst_filepath, 'w') as file:\n",
    "    json.dump(cropped_position_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearnenv",
   "language": "python",
   "name": "sklearnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
